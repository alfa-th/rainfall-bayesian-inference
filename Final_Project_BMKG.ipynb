{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_BMKG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hljlwMAVfqZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install -U scikit-learn\n",
        "# ^ Pake jika import gagal\n",
        "# ^ Setelah dirun, restart runtime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmi68OffwvOf",
        "colab_type": "code",
        "outputId": "78b86351-b227-4123-a4a8-25fecb37f461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# List yang berisi semua nama file\n",
        "excel_filenames = [bulan + \" 2018.xlsx\" for bulan in [\"Januari\", \"Februari\", \"Maret\", \n",
        "                                                       \"April\", \"Mei\", \"Juni\", \n",
        "                                                       \"Juli\", \"Agustus\", \"September\", \n",
        "                                                       \"Oktober\", \"November\", \"Desember\"]]\n",
        "\n",
        "# Mengambil file .xlsx dan mengubah .xslx menjadi dataframe\n",
        "def excelparser(excel_filename):\n",
        "  # Hapus header sebanyak 8 baris dan footer sebanyak 12 baris\n",
        "  return pd.read_excel(excel_filename, header = 8, skipfooter = 12)\n",
        "\n",
        "# Gabung file .xlsx menjadi 1 dataframe\n",
        "def excelcombiner(excel_filename):\n",
        "  # Buat list kosong yang akan menyimpan banyak dataframes\n",
        "  df_list = []\n",
        "  \n",
        "  # Iterasi semua file .xlsx untuk dibuat dataframenya dan dikumpulkan kedalam list df_list\n",
        "  for item in excel_filename:\n",
        "    df_list.append(excelparser(item))\n",
        "  \n",
        "  # Gabungkan semua isi df_list menjadi satu dataframe dan mulai hitungan index dari 0\n",
        "  return pd.concat(df_list, ignore_index = True)\n",
        "\n",
        "# Buat file csv dari semua file .xslx dengan mengambil list yang berisi nama .xslx\n",
        "def csv_create(excel_filename, output_filename):\n",
        "  # Ambil nama file excel yang akan dibuat ke csv lalu masukkan kedalam fungsi excelcombiner\n",
        "  df = excelcombiner(excel_filename)\n",
        "  \n",
        "  # Buat file csv dengan dataframe yang diambil tanpa memedulikan index\n",
        "  return df.to_csv(output_filename, index = False)\n",
        "\n",
        "# Buat file csv dari semua file .xslx \n",
        "csv_create(excel_filenames, \"training.csv\")\n",
        "\n",
        "# Data testing\n",
        "excel_filenames = [bulan + \" 2019.xlsx\" for bulan in [\"Januari\", \"Februari\"]]\n",
        "csv_create(excel_filenames, \"testing.csv\")\n",
        "\n",
        "# Preprocess csv yang dibuat agar mempunyai nama kolom yang dapat dimengerti dan format yang sesuai\n",
        "def csv_preprocess(csv_filename):\n",
        "  # Read filename dari argumen dan ambil\n",
        "  df = pd.read_csv(csv_filename)\n",
        "  \n",
        "  # Buang kolom tanggal\n",
        "  df = df.drop(columns=[\"Tanggal\"])\n",
        "  \n",
        "  # Ubah nama kolom\n",
        "  df.columns = [\"suhu_rendah\", \"suhu_tinggi\", \"lembap_rata\", \n",
        "                \"curah_hujan\",\"lama_sinar\", \"cepat_angin_rata\"]\n",
        "  \n",
        "  # Tukar nama kolom dan buat curah_hujan ke bagian kiri\n",
        "  df = df.reindex(columns=[\"suhu_rendah\", \"suhu_tinggi\", \"lembap_rata\", \n",
        "                           \"lama_sinar\", \"cepat_angin_rata\", \"curah_hujan\"])\n",
        "  \n",
        "  # Buang row apabila data tidak ada (8888.0 / NaN)\n",
        "  df = df.drop(df[(df.curah_hujan == 8888.0) | (np.isnan(df.curah_hujan)) | (np.isnan(df.suhu_rendah)) | (np.isnan(df.suhu_tinggi)) | (np.isnan(df.lama_sinar)) | (np.isnan(df.cepat_angin_rata))].index) \n",
        "  \n",
        "  \n",
        "  # Lakukan iterasi pada setiap row dan ubah nilai curah_hujan sesuai klasifikasi BMKG\n",
        "  for idx, row in df.iterrows():\n",
        "    if  df.loc[idx,'curah_hujan'] < 20:\n",
        "        df.loc[idx,'curah_hujan'] = \"ringan\"\n",
        "    elif df.loc[idx,'curah_hujan'] < 40:\n",
        "        df.loc[idx,'curah_hujan'] = \"sedang\"\n",
        "    else:\n",
        "        df.loc[idx,'curah_hujan'] = \"deras\"\n",
        "  \n",
        "  return df.reset_index(drop = True)\n",
        "\n",
        "# Lakukan fungsi preprocess terhadap file .csv\n",
        "csv_preprocess(\"testing.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2e29c3f99086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Buat file csv dari semua file .xslx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mcsv_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Data testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2e29c3f99086>\u001b[0m in \u001b[0;36mcsv_create\u001b[0;34m(excel_filename, output_filename)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcsv_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;31m# Ambil nama file excel yang akan dibuat ke csv lalu masukkan kedalam fungsi excelcombiner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexcelcombiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m# Buat file csv dengan dataframe yang diambil tanpa memedulikan index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2e29c3f99086>\u001b[0m in \u001b[0;36mexcelcombiner\u001b[0;34m(excel_filename)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Iterasi semua file .xlsx untuk dibuat dataframenya dan dikumpulkan kedalam list df_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcel_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcelparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Gabungkan semua isi df_list menjadi satu dataframe dan mulai hitungan index dari 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2e29c3f99086>\u001b[0m in \u001b[0;36mexcelparser\u001b[0;34m(excel_filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexcelparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Hapus header sebanyak 8 baris dan footer sebanyak 12 baris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipfooter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Gabung file .xlsx menjadi 1 dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     return io.parse(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Januari 2018.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVn-A4ATds8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Membuat dataframe yang berisi informasi standar defiasi dan rata-rata dari setiap kelas dan feature\n",
        "def generate_df_std_mean(csv_filename):\n",
        "  # Mengambil dataframe yang telah di preprocess\n",
        "  df = csv_preprocess(csv_filename)\n",
        "  \n",
        "  # Membuat list berisi himpunan dataframe\n",
        "  df_list = []\n",
        "  \n",
        "  # Menambahkan dataframe khusus tabel khusus dengan yang mempunyai nilai kelas masing-masing serta fiturnya\n",
        "  for klasifikasi in df[df.columns[-1]].unique():\n",
        "    df_list.append(df.loc[df[df.columns[-1]] == klasifikasi])\n",
        "    df_list.append(df.loc[df[df.columns[-1]] == klasifikasi])\n",
        "  \n",
        "  # Mengaplikasikan rumus pada list dataframe untuk menghasilkan standar deviasi dan rata-rata untuk setiap kelas dan fitur\n",
        "  for index, df in enumerate(df_list):\n",
        "    for column in df.columns:\n",
        "      if column != df.columns[-1] and index % 2 == 0:\n",
        "        average_col = df.loc[:,column].mean()\n",
        "        df.loc[:,column] = average_col\n",
        "      elif column != df.columns[-1]:\n",
        "        average_col = df.loc[:,column].std()\n",
        "        df.loc[:,column] = average_col\n",
        "        \n",
        "  # Mengmperbaiki format dataframe agar sesuai dan mudah diolah        \n",
        "  df = pd.concat(df_list, ignore_index = True).drop_duplicates().reset_index(drop = True)\n",
        "  new_index = zip(df.iloc[:, -1], [\"rata\" if index % 2 == 0 else \"std\" for index in range(len(df))])\n",
        "  new_index = pd.MultiIndex.from_tuples(new_index)\n",
        "  df = df.drop(columns = df.columns[-1])\n",
        "  df = pd.DataFrame(df.values, index=new_index, columns=df.columns)\n",
        "  \n",
        "  # Mengembalikan dataframe\n",
        "  return df\n",
        "\n",
        "generate_df_std_mean(\"training.csv\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za7bDUFCL0id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi Gaussian Naive Bayes yang sesuai dengan isi paper\n",
        "def function_gnb(x, std_feature, mean_feature):\n",
        "  return (1 / (std_feature * np.sqrt(2 * np.pi))) * (np.e ** (-(x - mean_feature)**2/(2 * (std_feature**2))))\n",
        "\n",
        "# 1. Fungsi prediksi yang akan mengembalikan prediksi setiap kelas dengan nilai prediksinya\n",
        "# 2. Fungsi mengambil fitur yang akan diprediksi dalam bentuk dictionary, dan mengambil \n",
        "#    dataframe yang berisi nilai standar deviasi dan rata-rata setiap kelas dan fitur\n",
        "def predict_gnb(dict_feature, df_std_mean):\n",
        "  \n",
        "  # Ambil kelas yang ada pada dataframe\n",
        "  predict_class = set([item[0] for item in list(df_std_mean.index)])\n",
        "  \n",
        "  # Ambil keys dari input dict\n",
        "  actual_predict = dict.fromkeys(predict_class)\n",
        "\n",
        "  \n",
        "  # Mengiterasi dan mengaplikasikan rumus gaussian NB untuk setiap fitur berdasarkan fitur input\n",
        "  for item in actual_predict.copy():\n",
        "    semi_predict = []\n",
        "    \n",
        "    for key, value in dict_feature.items():\n",
        "      semi_predict.append(function_gnb(value,\n",
        "                                       df_std_mean.loc[(item, \"std\"), key], \n",
        "                                       df_std_mean.loc[(item, \"rata\"), key]))\n",
        "      \n",
        "    actual_predict[item] = np.prod(semi_predict)\n",
        "  \n",
        "  return actual_predict\n",
        " \t\n",
        "# Fungsi yang menghasilkan keys yang mempunyai nilai tertinggi\n",
        "def highest_dict(_dict):\n",
        "  return max(_dict, key = lambda key: _dict[key])\n",
        "\n",
        "\n",
        "prediksi = {\"suhu_rendah\": 25.8,\"suhu_tinggi\": 32.4,\"lembap_rata\": 79,\"lama_sinar\": 4.6,\"cepat_angin_rata\": 1}\n",
        "prediksi_dict = predict_gnb(prediksi, generate_df_std_mean(\"training.csv\"))\n",
        "print(prediksi_dict)\n",
        "highest_dict(prediksi_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHiZs-f8ltAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi untuk membuat tuple yang berisi list hasil_benar, list hasil_prediksi,list dan kelas\n",
        "def generate_pred_true(csv_predict, csv_filename):\n",
        "  # Ambil dataframe dari csv\n",
        "  df = csv_preprocess(csv_predict)\n",
        "  \n",
        "  # Ambil dataframs std dan rata-rata dari csv\n",
        "  df_std_mean = generate_df_std_mean(\"training.csv\")\n",
        "  \n",
        "  # Ambil list hasil benar menggunakan fungsi iloc\n",
        "  true = list(df.iloc[:,-1])\n",
        "  \n",
        "  # Buat list kosong yang akan diisi prediksi\n",
        "  pred = []\n",
        "  \n",
        "  # Buat list berisi kelas\n",
        "  labels = df[df.columns[-1]].unique()\n",
        "  \n",
        "  # Buat dictionary dari setiap row dataframe\n",
        "  dict_list = csv_preprocess(csv_predict).iloc[:,:-1].to_dict('records')\n",
        "  \n",
        "  # Aplikasikan fungsi dari setiap dictionary yang dibuat dari setiap row dataframe kedalam fungsi predict_gnb\n",
        "  for dict_pred in dict_list:\n",
        "    pred.append(highest_dict(predict_gnb(dict_pred, df_std_mean)))\n",
        "    \n",
        "  # Kembalikan tuple yang berisi list hasil_benar, list hasil_prediksi,list dan kelas\n",
        "  return (true, pred, df[df.columns[-1]].unique())\n",
        "\n",
        "tp_tuple = generate_pred_true(\"testing.csv\",\"training.csv\")\n",
        "print(tp_tuple[1], tp_tuple[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eDKiBK8MBuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fungsi untuk membuat laporan confusion matrix, akurasi, presisi, recall, dan error ratio\n",
        "def generate_report(tp_tuple):\n",
        "  # Ambil nilai dari tuple\n",
        "  true, pred, labels = tp_tuple\n",
        "  \n",
        "  # Aplikasikan semua variabel kedalam fungsi yang disediakan library scikit-learn\n",
        "  cf_matrix = confusion_matrix(true, pred, labels = labels)\n",
        "  accuracy = jaccard_score(true, pred, average = None, labels = labels)\n",
        "  precision = precision_score(true, pred, average = None, labels = labels)\n",
        "  recall = recall_score(true, pred, average = None, labels = labels)\n",
        "  error_ratio = np.array([1 - rate for rate in accuracy])\n",
        "  \n",
        "  # Print hasil\n",
        "  print(\"Confussion Matrix : (dengan nilai Ringan, Sedang, Deras secara berurutan)\\n\", cf_matrix)\n",
        "  print(\"\\nAkurasi : \\t\", accuracy)\n",
        "  print(\"Precision : \\t\", precision)\n",
        "  print(\"Recall : \\t\", recall)\n",
        "  print(\"Error Ratio : \\t\", error_ratio) \n",
        "  \n",
        "generate_report(tp_tuple)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVCibHZBU-XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}